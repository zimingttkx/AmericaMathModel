# 模型评估 AI Prompt 模板（详细版）

> **使用说明**: 本文件包含模型评估、验证、调试等环节的详细Prompt模板。

---

## 📊 场景1: 分类模型评估

### 完整评估Prompt

```
请对分类模型进行全面评估。

【模型信息】
模型类型：【分类模型名称】
预测值：y_pred
真实值：y_true
预测概率：y_pred_proba（如果有）

【基础评估指标】

1. 准确率（Accuracy）
   - 定义：正确预测的比例
   - 计算：accuracy = (TP + TN) / (TP + TN + FP + FN)
   - 代码：from sklearn.metrics import accuracy_score

2. 精确率（Precision）
   - 定义：预测为正的样本中，真正为正的比例
   - 计算：precision = TP / (TP + FP)
   - 代码：from sklearn.metrics import precision_score

3. 召回率（Recall）
   - 定义：真正为正的样本中，被正确预测的比例
   - 计算：recall = TP / (TP + FN)
   - 代码：from sklearn.metrics import recall_score

4. F1-Score
   - 定义：精确率和召回率的调和平均
   - 计算：f1 = 2 * (precision * recall) / (precision + recall)
   - 代码：from sklearn.metrics import f1_score

5. 混淆矩阵
   - 展示：TP, TN, FP, FN的数量
   - 代码：from sklearn.metrics import confusion_matrix

【高级评估指标】

6. ROC曲线和AUC
   - ROC曲线：FPR vs TPR
   - AUC：曲线下面积
   - 代码：from sklearn.metrics import roc_curve, auc, roc_auc_score

7. PR曲线和AP
   - PR曲线：Precision vs Recall
   - AP：平均精度
   - 代码：from sklearn.metrics import precision_recall_curve, average_precision_score

8. 分类报告
   - 每个类别的precision, recall, f1-score
   - 宏平均和加权平均
   - 代码：from sklearn.metrics import classification_report

【实现步骤】

步骤1：基础评估
```python
from sklearn.metrics import (accuracy_score, precision_score, 
                             recall_score, f1_score, confusion_matrix)

# 计算指标
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='binary')
recall = recall_score(y_true, y_pred, average='binary')
f1 = f1_score(y_true, y_pred, average='binary')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
```

步骤2：混淆矩阵可视化
```python
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
```

步骤3：ROC曲线
```python
from sklearn.metrics import roc_curve, auc

fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba[:, 1])
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()
```

步骤4：分类报告
```python
from sklearn.metrics import classification_report

report = classification_report(y_true, y_pred, 
                            target_names=['Class 0', 'Class 1'])
print(report)
```

【输出要求】
1. 所有评估指标的数值
2. 混淆矩阵热力图
3. ROC曲线图
4. PR曲线图
5. 完整的分类报告
```

### 多分类评估完整Prompt

```
请对多分类模型进行评估。

【数据信息】
类别数：【3个或更多】
类别名称：【Class1, Class2, Class3, ...】
y_pred, y_true

【评估要求】
1. 每个类别的precision, recall, f1
2. 宏平均和加权平均
3. 混淆矩阵热力图
4. 分类报告
5. 每个类别的ROC曲线（One-vs-Rest）

【代码实现】
```python
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier

# 分类报告
report = classification_report(y_true, y_pred, 
                            target_names=class_names)
print(report)

# 混淆矩阵
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', 
            xticklabels=class_names,
            yticklabels=class_names,
            cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

# One-vs-Rest ROC曲线
y_score_bin = label_binarize(y_true, classes=[0, 1, 2])
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(len(class_names)):
    fpr[i], tpr[i], _ = roc_curve(y_score_bin[:, i], y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])
```
```

---

## 📈 场景2: 回归模型评估

### 完整评估Prompt

```
请对回归模型进行全面评估。

【模型信息】
预测值：y_pred
真实值：y_true
残差：residuals = y_true - y_pred

【基础评估指标】

1. MSE（均方误差）
   - 计算：mean((y_true - y_pred)**2)
   - 代码：from sklearn.metrics import mean_squared_error

2. RMSE（均方根误差）
   - 计算：sqrt(MSE)
   - 单位：与目标变量相同
   - 解释：预测值的平均误差

3. MAE（平均绝对误差）
   - 计算：mean(abs(y_true - y_pred))
   - 代码：from sklearn.metrics import mean_absolute_error
   - 对异常值更鲁棒

4. R²（决定系数）
   - 计算：1 - (sum((y_true - y_pred)^2) / sum((y_true - y_mean)^2))
   - 范围：(-∞, 1]，越接近1越好
   - 解释：模型解释的方差比例

5. MAPE（平均绝对百分比误差）
   - 计算：mean(|y_true - y_pred| / y_true) * 100
   - 单位：百分比
   - 优点：尺度不变

6. Adjusted R²（调整R²）
   - 考虑特征数量的R²
   - 惩罚过多特征

【实现步骤】

步骤1：计算所有指标
```python
from sklearn.metrics import (mean_squared_error, mean_absolute_error, 
                             r2_score, mean_absolute_percentage_error)

mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)
mape = mean_absolute_percentage_error(y_true, y_pred)

print(f"MSE: {mse:.4f}")
print(f"RMSE: {rmse:.4f}")
print(f"MAE: {
```

### 残差分析完整Prompt

```
请进行详细的残差分析。

【残差信息】
残差 = y_true - y_pred

【分析内容】

1. 残差统计
   - 均值：应接近0
   - 标准差：应较小
   - 偏度：应接近0（正态分布）
   - 峰度：应接近3（正态分布）

2. 残差直方图
   - 检查正态性
   - 代码：
   ```python
   plt.figure(figsize=(10, 6))
   plt.hist(residuals, bins=30, edgecolor='white')
   plt.xlabel('Residuals')
   plt.ylabel('Frequency')
   plt.title('Distribution of Residuals')
   plt.axvline(x=0, color='red', linestyle='--')
   plt.show()
   ```

3. Q-Q图（正态性检验）
   ```python
   from scipy import stats
   stats.probplot(residuals, dist="norm", plot=plt)
   plt.show()
   ```

4. 残差vs预测值图
   - 检查同方差性
   - 残差应随机分布在0附近
   - 不应有明显模式
   ```python
   plt.scatter(y_pred, residuals)
   plt.axhline(y=0, color='red', linestyle='--')
   plt.xlabel('Predicted Values')
   plt.ylabel('Residuals')
   plt.title('Residual Plot')
   plt.show()
   ```

5. 残差vs顺序图
   - 检查独立性
   - 不应有自相关

【正态性检验】
```python
from scipy.stats import shapiro, normaltest

# Shapiro-Wilk检验
stat, p_value = shapiro(residuals)
print(f"Shapiro-Wilk p-value: {p_value}")

# D'Agostino's检验
stat2, p_value2 = normaltest(residuals)
print(f"D'Agostino's p-value: {p_value2}")
```

【输出要求】
1. 残差统计表
2. 残差直方图
3. Q-Q图
4. 残差vs预测值图
5. 正态性检验结果
6. 同方差性检验
```

---

## 🔍 场景3: 交叉验证

### K折交叉验证完整Prompt

```
请执行K折交叉验证。

【数据信息】
模型：【模型对象】
K值：5或10
评分指标：accuracy / f1 / roc_auc / neg_mean_squared_error

【实现步骤】

步骤1：基础交叉验证
```python
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate

# 方法1：只返回分数
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print("每折得分:", scores)
print("平均分:", scores.mean())
print("标准差:", scores.std())
```

步骤2：返回更多信息
```python
scoring = ['accuracy', 'precision', 'recall', 'f1']
cv_results = cross_validate(model, X, y, cv=5, 
                           scoring=scoring, return_train_score=True)

# 显示结果
import pandas as pd
cv_df = pd.DataFrame(cv_results)
print(cv_df)
```

步骤3：可视化交叉验证结果
```python
plt.figure(figsize=(10, 6))
plt.bar(range(1, 6), scores)
plt.axhline(y=scores.mean(), color='red', linestyle='--')
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.title('Cross-Validation Scores')
plt.show()
```

【分层K折交叉验证】
```python
from sklearn.model_selection import StratifiedKFold

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')
```

【时间序列交叉验证】
```python
from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
scores = cross_val_score(model, X, y, cv=tscv)
```

【输出要求】
1. 每折得分
2. 平均得分和标准差
3. 得分可视化
4. 训练集vs验证集得分对比
```

---

## 📉 场景4: 学习曲线

### 学习曲线完整分析Prompt

```
请绘制和分析学习曲线。

【目的】
- 诊断过拟合/欠拟合
- 确定是否需要更多数据
- 模型是否收敛

【参数设置】
train_sizes：训练集大小比例，如[0.1, 0.2, 0.3, 0.5, 0.7, 0.9]
cv：交叉验证折数
scoring：评分指标

【实现步骤】

步骤1：绘制学习曲线
```python
from sklearn.model_selection import learning_curve

train_sizes, train_scores, val_scores = learning_curve(
    model, X, y,
    train_sizes=train_sizes,
    cv=5,
    scoring='accuracy',
    shuffle=True,
    random_state=42
)

# 计算均值和标准差
train_mean = train_scores.mean(axis=1)
train_std = train_scores.std(axis=1)
val_mean = val_scores.mean(axis=1)
val_std = val_scores.std(axis=1)
```

步骤2：可视化
```python
plt.figure(figsize=(10, 6))
plt.fill_between(train_sizes, train_mean - train_std, 
                 train_mean + train_std, alpha=0.1, color='r')
plt.fill_between(train_sizes, val_mean - val_std,
                 val_mean + val_std, alpha=0.1, color='g')
plt.plot(train_sizes, train_mean, 'o-', color='r', label='Training score')
plt.plot(train_sizes, val_mean, 'o-', color='g', label='Validation score')
plt.xlabel('Training Set Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve')
plt.legend()
plt.grid(True)
plt.show()
```

步骤3：分析学习曲线
```
【分析要点】

1. 欠拟合（High Bias）
   - 训练得分低
   - 验证得分低
   - 两者接近
   - 建议：增加模型复杂度、添加更多特征

2. 过拟合（High Variance）
   - 训练得分高
   - 验证得分低
   - 差距大
   - 建议：更多训练数据、正则化、简化模型

3. 适合
   - 训练得分高
   - 验证得分接近训练得分
   - 两者都较高
   - 模型良好

【诊断问题】
1. 是否过拟合？
2. 是否欠拟合？
3. 是否需要更多数据？
4. 模型是否收敛？
```

【输出要求】
1. 学习曲线图
2. 训练/验证得分表
3. 详细分析和建议
```

---

## 📊 场景5: 验证曲线

### 验证曲线完整分析Prompt

```
请绘制验证曲线，分析超参数影响。

【超参数名称】
参数名：【如：n_estimators, max_depth, C等】
参数范围：【param_range】

【实现步骤】

步骤1：定义参数范围
```python
param_range = np.linspace(1, 100, 10)  # 示例
```

步骤2：绘制验证曲线
```python
from sklearn.model_selection import validation_curve

train_scores, val_scores = validation_curve(
    model, X, y,
    param_name='n_estimators',
    param_range=param_range,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)
```

步骤3：可视化
```python
train_mean = train_scores.mean(axis=1)
train_std = train_scores.std(axis=1)
val_mean = val_scores.mean(axis=1)
val_std = val_scores.std(axis=1)

plt.figure(figsize=(10, 6))
plt.plot(param_range, train_mean, 'o-', color='r', label='Training score')
plt.fill_between(param_range, train_mean - train_std,
                 train_mean + train_std, alpha=0.1, color='r')
plt.plot(param_range, val_mean, 'o-', color='g', label='Validation score')
plt.fill_between(param_range, val_mean - val_std,
                 val_mean + val_std, alpha=0.1, color='g')
plt.xlabel('n_estimators')
plt.ylabel('Accuracy')
plt.title('Validation Curve')
plt.legend()
plt.grid(True)
plt.show()
```

步骤4：分析
```
【分析】
1. 最优参数值
2. 过拟合区域（训练>>验证）
3. 欠拟合区域（两者都低）
4. 最优区域（两者都高且接近）
```

【输出要求】
1. 验证曲线图
2. 最优参数建议
3. 过拟合/欠拟合分析
```

---

## 🎯 场景6: 模型对比

### 多模型对比完整Prompt

```
请对比多个模型的性能。

【模型列表】
模型1：【模型名称和参数】
模型2：【模型名称和参数】
模型3：【模型名称和参数】
模型4：【模型名称和参数】

【评估指标】
分类：accuracy, precision, recall, f1, auc
回归：mse, rmse, mae, r2

【实现步骤】

步骤1：训练所有模型
```python
models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'XGBoost': XGBClassifier(random_state=42)
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    # 计算指标
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    results[name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1
    }
```

步骤2：创建对比表格
```python
import pandas as pd
results_df = pd.DataFrame(results).T
print(results_df)
```

步骤3：可视化对比
```python
results_df.plot(kind='bar', figsize=(12, 6))
plt.title('Model Performance Comparison')
plt.ylabel('Score')
plt.legend(loc='lower right')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

步骤4：统计显著性检验
```python
from scipy.stats import ttest_ind

# 模型A vs 模型B
scores_a = cross_val_score(model_a, X, y, cv=5)
scores_b = cross_val_score(model_b, X, y, cv=5)
t_stat, p_value = ttest_ind(scores_a, scores_b)
print(f"p-value: {p_value}")
```

【输出要求】
1. 性能对比表格
2. 柱状图对比
3. 排名和推荐
4. 统计显著性检验
5. 改进建议
```

---

## 🔍 场景7: 错误分析

### 误分类分析完整Prompt

```
请分析模型的预测错误。

【数据信息】
y_true, y_pred, X_test

【分析内容】

1. 错误样本识别
   - 找出所有错误预测的样本
   - 代码：errors = y_true != y_pred
   - X_errors = X_test[errors]

2. 错误类型统计
   - 假阳性（FP）：实际为0，预测为1
   - 假阴性（FN）：实际为1，预测为0
   - 混淆矩阵分析

3. 困难样本分析
   - 误分类样本的特征特征
   - 是否集中在某些区域
   - 特征值分布

4. 可视化错误样本
   - 2D投影（用PCA降维后）
   - 标记错误样本
   - 分析聚类模式

【实现步骤】
```python
# 识别错误样本
errors = y_test != y_pred
error_indices = np.where(errors)[0]

# 分析错误样本的特征
print("错误样本数量:", len(error_indices))
print("错误样本索引:", error_indices[:10])

# PCA降维可视化
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_2d = pca.fit_transform(X_test)

plt.figure(figsize=(10, 6))
colors = ['green' if not e else 'red' for e in errors]
plt.scatter(X_2d[:, 0], X_2d[:, 1], c=colors, alpha=0.6)
plt.title('Error Analysis (2D PCA Projection)')
plt.show()
```

【输出要求】
1. 错误样本统计
2. 错误样本特征分析
3. 可视化展示
4. 改进建议
```

---

## 💡 完整评估流程Prompt

### 端到端模型评估完整模板

```
请对模型进行完整的端到端评估。

【评估流程】

步骤1：基础性能评估（5分钟）
- 计算所有核心指标
- 生成混淆矩阵
- 输出分类报告

步骤2：交叉验证（10分钟）
- 5折交叉验证
- 输出得分均值和标准差
- 分析模型稳定性

步骤3：学习曲线分析（10分钟）
- 绘制学习曲线
- 诊断过拟合/欠拟合
- 提供改进建议

步骤4：校准曲线（如需要）（15分钟）
- 二分类：绘制ROC曲线，计算AUC
- 绘制Precision-Recall曲线
- 计算AP值

步骤5：特征重要性分析（10分钟）
- 计算特征重要性
- 可视化展示
- 解释特征含义

步骤6：错误分析（10分钟）
- 识别错误样本
- 分析错误模式
- 提供改进方向

步骤7：模型解释（15分钟）
- SHAP值分析
- 单个预测解释
- 特征交互分析

步骤8：对比基准模型（10分钟）
- 与简单模型对比
- 性能提升分析
- 成本效益评估

【输出报告】
=== 模型评估完整报告 ===

一、基础性能
- 准确率：【值】
- 精确率：【值】
- 召回率：【值】
- F1-Score：【值】
- AUC：【值】

二、交叉验证
- 平均准确率：【值】
- 标准差：【值】

三、学习曲线分析
- 模型状态：【适合/过拟合/欠拟合】
- 建议：【改进方向】

四、特征重要性
Top 10特征:
1. 【特征】: 【重要性】
2. 【特征】: 【重要性】
...

五、错误分析
- 主要错误类型: 【描述】
- 错误样本特征: 【描述】
- 改进建议: 【建议】

六、对比基准
- 基准模型性能: 【值】
- 本模型性能: 【值】
- 提升: 【值】%

七、结论
- 模型优势: 【2-3点】
- 模型劣势: 【2-3点】
- 总体评价: 【评分1-5星】
- 应用建议: 【建议】
```

---

**文件结束**

本文件涵盖了模型评估的完整流程，包括基础评估、交叉验证、学习曲线、验证曲线、模型对比、错误分析等，每个模板都包含详细的实现步骤和分析要求。
