{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题4: 新赛制提议 (Proposing a Better System)\n",
    "\n",
    "## 研究目标\n",
    "设计一个兼顾**公平性**（技术好的选手应获得认可）和**观赏性**（保持悬念和粉丝参与感）的新评分系统。\n",
    "\n",
    "## 三种方案\n",
    "- **方案A**: 加权Borda计数法 (Weighted Borda Count)\n",
    "- **方案B**: Elo等级分动态权重系统 (Elo-based Dynamic Weighting)\n",
    "- **方案C**: 双重阈值淘汰制 (Dual Threshold Elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "SCIENTIFIC_COLORS = ['#E64B35', '#4DBBD5', '#00A087', '#3C5488', '#F39B7F', '#8491B4']\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print('环境配置完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../../data/processed/粉丝投票分析.xlsx')\n",
    "print(f'数据维度: {df.shape}')\n",
    "print(f'赛季范围: {df[\"赛季\"].min()} - {df[\"赛季\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 评估指标定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringSystemEvaluator:\n",
    "    \"\"\"\n",
    "    评分系统评估器\n",
    "    评估维度:\n",
    "    1. 公平性 (Fairness): 技术好的选手排名应靠前\n",
    "    2. 观赏性 (Entertainment): 保持悬念，避免一边倒\n",
    "    3. 稳定性 (Stability): 结果不应过于波动\n",
    "    4. 粉丝参与度 (Fan Engagement): 粉丝投票应有实际影响\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def fairness_score(self, judge_ranks, final_ranks):\n",
    "        \"\"\"公平性: 评委排名与最终排名的相关性\"\"\"\n",
    "        tau, _ = kendalltau(judge_ranks, final_ranks)\n",
    "        return (tau + 1) / 2  # 归一化到0-1\n",
    "    \n",
    "    def entertainment_score(self, weekly_changes):\n",
    "        \"\"\"观赏性: 排名变化的标准差（适度变化=高观赏性）\"\"\"\n",
    "        std = np.std(weekly_changes)\n",
    "        # 适度变化最好，太稳定或太混乱都不好\n",
    "        optimal_std = 2.0\n",
    "        return 1 - min(abs(std - optimal_std) / optimal_std, 1)\n",
    "    \n",
    "    def stability_score(self, rankings_history):\n",
    "        \"\"\"稳定性: 连续周排名变化的平均值\"\"\"\n",
    "        if len(rankings_history) < 2:\n",
    "            return 1.0\n",
    "        changes = np.abs(np.diff(rankings_history))\n",
    "        return 1 / (1 + np.mean(changes))\n",
    "    \n",
    "    def fan_engagement_score(self, fan_influence):\n",
    "        \"\"\"粉丝参与度: 粉丝投票对最终结果的影响程度\"\"\"\n",
    "        return min(fan_influence, 1.0)\n",
    "    \n",
    "    def overall_score(self, fairness, entertainment, stability, engagement, weights=None):\n",
    "        \"\"\"综合评分\"\"\"\n",
    "        if weights is None:\n",
    "            weights = [0.3, 0.25, 0.2, 0.25]  # 公平性权重最高\n",
    "        return np.dot([fairness, entertainment, stability, engagement], weights)\n",
    "\n",
    "evaluator = ScoringSystemEvaluator()\n",
    "print('评估器初始化完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 方案A: 加权Borda计数法\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 加权Borda计数法理论\n",
    "\n",
    "**传统Borda计数**: 第1名得N分，第2名得N-1分，...，最后一名得1分\n",
    "\n",
    "**改进: 引入分差系数**\n",
    "$$Score_i = \\sum_{j} w_j \\cdot B_j(i) \\cdot \\alpha_j$$\n",
    "\n",
    "其中:\n",
    "- $B_j(i)$: 选手i在评判j下的Borda分数\n",
    "- $w_j$: 评判j的权重（评委/粉丝）\n",
    "- $\\alpha_j$: 分差系数，反映与下一名的差距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedBordaSystem:\n",
    "    \"\"\"\n",
    "    加权Borda计数法\n",
    "    兼顾名次和表现差距，防止一人独大\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, judge_weight=0.5, fan_weight=0.5, gap_factor=0.1):\n",
    "        self.judge_weight = judge_weight\n",
    "        self.fan_weight = fan_weight\n",
    "        self.gap_factor = gap_factor  # 分差系数\n",
    "    \n",
    "    def borda_score(self, ranks, n):\n",
    "        \"\"\"计算Borda分数: 第1名得n分，最后一名得1分\"\"\"\n",
    "        return n - ranks + 1\n",
    "    \n",
    "    def gap_coefficient(self, scores):\n",
    "        \"\"\"计算分差系数\"\"\"\n",
    "        sorted_scores = np.sort(scores)[::-1]\n",
    "        gaps = np.diff(sorted_scores)\n",
    "        # 归一化分差\n",
    "        if len(gaps) > 0 and np.max(np.abs(gaps)) > 0:\n",
    "            normalized_gaps = gaps / np.max(np.abs(gaps))\n",
    "            coefficients = 1 + self.gap_factor * np.abs(normalized_gaps)\n",
    "            return np.concatenate([[1.0], coefficients])\n",
    "        return np.ones(len(scores))\n",
    "    \n",
    "    def calculate_final_score(self, judge_scores, fan_votes):\n",
    "        \"\"\"计算最终得分\"\"\"\n",
    "        n = len(judge_scores)\n",
    "        \n",
    "        # 评委Borda分数\n",
    "        judge_ranks = stats.rankdata(-judge_scores, method='min')\n",
    "        judge_borda = self.borda_score(judge_ranks, n)\n",
    "        judge_gap = self.gap_coefficient(judge_scores)\n",
    "        \n",
    "        # 粉丝Borda分数\n",
    "        fan_ranks = stats.rankdata(-fan_votes, method='min')\n",
    "        fan_borda = self.borda_score(fan_ranks, n)\n",
    "        fan_gap = self.gap_coefficient(fan_votes)\n",
    "        \n",
    "        # 加权综合\n",
    "        final_score = (self.judge_weight * judge_borda * judge_gap + \n",
    "                       self.fan_weight * fan_borda * fan_gap)\n",
    "        \n",
    "        return final_score, stats.rankdata(-final_score, method='min')\n",
    "\n",
    "borda_system = WeightedBordaSystem(judge_weight=0.5, fan_weight=0.5, gap_factor=0.1)\n",
    "print('加权Borda系统初始化完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 方案B: Elo等级分动态权重系统\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Elo动态权重系统理论\n",
    "\n",
    "**核心思想**: 引入时间维度，随着赛季进行动态调整权重\n",
    "\n",
    "**权重公式**:\n",
    "$$w_{judge}(t) = w_0 - \\lambda \\cdot t$$\n",
    "$$w_{fan}(t) = 1 - w_{judge}(t)$$\n",
    "\n",
    "**Elo积分更新**:\n",
    "$$R_{new} = R_{old} + K \\cdot (S - E)$$\n",
    "\n",
    "其中:\n",
    "- $t$: 当前周数\n",
    "- $\\lambda$: 权重衰减系数\n",
    "- $K$: Elo更新系数\n",
    "- $S$: 实际表现\n",
    "- $E$: 期望表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EloDynamicSystem:\n",
    "    \"\"\"\n",
    "    Elo等级分动态权重系统\n",
    "    随赛季进行调整评委/粉丝权重，增加后期悬念\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initial_judge_weight=0.7, decay_rate=0.03, k_factor=32, initial_elo=1500):\n",
    "        self.initial_judge_weight = initial_judge_weight\n",
    "        self.decay_rate = decay_rate\n",
    "        self.k_factor = k_factor\n",
    "        self.initial_elo = initial_elo\n",
    "        self.elo_ratings = {}\n",
    "    \n",
    "    def get_weights(self, week, total_weeks=10):\n",
    "        \"\"\"获取当前周的权重\"\"\"\n",
    "        progress = week / total_weeks\n",
    "        judge_weight = max(0.3, self.initial_judge_weight - self.decay_rate * week)\n",
    "        fan_weight = 1 - judge_weight\n",
    "        return judge_weight, fan_weight\n",
    "    \n",
    "    def expected_score(self, rating_a, rating_b):\n",
    "        \"\"\"计算期望得分\"\"\"\n",
    "        return 1 / (1 + 10 ** ((rating_b - rating_a) / 400))\n",
    "    \n",
    "    def update_elo(self, contestant, actual_rank, n_contestants):\n",
    "        \"\"\"更新Elo等级分\"\"\"\n",
    "        if contestant not in self.elo_ratings:\n",
    "            self.elo_ratings[contestant] = self.initial_elo\n",
    "        \n",
    "        # 实际表现: 排名越高得分越高\n",
    "        actual_score = (n_contestants - actual_rank) / (n_contestants - 1)\n",
    "        expected = 0.5  # 简化: 期望中等表现\n",
    "        \n",
    "        self.elo_ratings[contestant] += self.k_factor * (actual_score - expected)\n",
    "        return self.elo_ratings[contestant]\n",
    "    \n",
    "    def calculate_final_score(self, contestants, judge_scores, fan_votes, week, total_weeks=10):\n",
    "        \"\"\"计算最终得分\"\"\"\n",
    "        judge_weight, fan_weight = self.get_weights(week, total_weeks)\n",
    "        n = len(contestants)\n",
    "        \n",
    "        # 归一化得分\n",
    "        judge_norm = (judge_scores - judge_scores.min()) / (judge_scores.max() - judge_scores.min() + 1e-6)\n",
    "        fan_norm = (fan_votes - fan_votes.min()) / (fan_votes.max() - fan_votes.min() + 1e-6)\n",
    "        \n",
    "        # Elo加成\n",
    "        elo_bonus = np.array([self.elo_ratings.get(c, self.initial_elo) for c in contestants])\n",
    "        elo_norm = (elo_bonus - elo_bonus.min()) / (elo_bonus.max() - elo_bonus.min() + 1e-6)\n",
    "        \n",
    "        # 综合得分\n",
    "        final_score = judge_weight * judge_norm + fan_weight * fan_norm + 0.1 * elo_norm\n",
    "        \n",
    "        return final_score, stats.rankdata(-final_score, method='min')\n",
    "\n",
    "elo_system = EloDynamicSystem(initial_judge_weight=0.7, decay_rate=0.03)\n",
    "print('Elo动态系统初始化完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 方案C: 双重阈值淘汰制\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 双重阈值淘汰制理论\n",
    "\n",
    "**核心规则**:\n",
    "1. **豁免区**: 评委分排名前K名获得\"豁免权\"，本周不会被淘汰\n",
    "2. **淘汰区**: 剩余选手完全由粉丝投票决定淘汰\n",
    "\n",
    "**优势**:\n",
    "- 公平性: 技术最好的选手保证进入决赛\n",
    "- 观赏性: 中间选手的命运由粉丝决定，增加悬念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualThresholdSystem:\n",
    "    \"\"\"\n",
    "    双重阈值淘汰制\n",
    "    评委分前K名获得豁免，其余由粉丝决定\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, immunity_ratio=0.3):\n",
    "        self.immunity_ratio = immunity_ratio  # 豁免比例\n",
    "    \n",
    "    def get_immunity_count(self, n_contestants):\n",
    "        \"\"\"计算豁免人数\"\"\"\n",
    "        return max(1, int(n_contestants * self.immunity_ratio))\n",
    "    \n",
    "    def determine_elimination(self, contestants, judge_scores, fan_votes):\n",
    "        \"\"\"确定淘汰选手\"\"\"\n",
    "        n = len(contestants)\n",
    "        immunity_count = self.get_immunity_count(n)\n",
    "        \n",
    "        # 评委排名\n",
    "        judge_ranks = stats.rankdata(-judge_scores, method='min')\n",
    "        \n",
    "        # 豁免选手 (评委分前K名)\n",
    "        immune_mask = judge_ranks <= immunity_count\n",
    "        immune_contestants = [c for c, m in zip(contestants, immune_mask) if m]\n",
    "        \n",
    "        # 非豁免选手中，粉丝投票最低者被淘汰\n",
    "        at_risk_indices = np.where(~immune_mask)[0]\n",
    "        if len(at_risk_indices) == 0:\n",
    "            # 所有人都豁免，淘汰粉丝投票最低者\n",
    "            eliminated_idx = np.argmin(fan_votes)\n",
    "        else:\n",
    "            at_risk_fan_votes = fan_votes[at_risk_indices]\n",
    "            eliminated_idx = at_risk_indices[np.argmin(at_risk_fan_votes)]\n",
    "        \n",
    "        eliminated = contestants[eliminated_idx]\n",
    "        \n",
    "        return {\n",
    "            'immune': immune_contestants,\n",
    "            'eliminated': eliminated,\n",
    "            'eliminated_idx': eliminated_idx,\n",
    "            'immunity_count': immunity_count\n",
    "        }\n",
    "    \n",
    "    def calculate_final_score(self, contestants, judge_scores, fan_votes):\n",
    "        \"\"\"计算综合得分（用于排名展示）\"\"\"\n",
    "        n = len(contestants)\n",
    "        immunity_count = self.get_immunity_count(n)\n",
    "        \n",
    "        judge_ranks = stats.rankdata(-judge_scores, method='min')\n",
    "        fan_ranks = stats.rankdata(-fan_votes, method='min')\n",
    "        \n",
    "        # 豁免选手得分加成\n",
    "        immunity_bonus = np.where(judge_ranks <= immunity_count, 100, 0)\n",
    "        \n",
    "        # 综合得分\n",
    "        final_score = immunity_bonus + (n - fan_ranks + 1)\n",
    "        \n",
    "        return final_score, stats.rankdata(-final_score, method='min')\n",
    "\n",
    "dual_threshold_system = DualThresholdSystem(immunity_ratio=0.3)\n",
    "print('双重阈值系统初始化完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part II: 仿真对比实验\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 准备仿真数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_simulation_data(df, season):\n",
    "    \"\"\"\n",
    "    准备单赛季仿真数据\n",
    "    关键修复: 排除评委分为0的选手\n",
    "    \"\"\"\n",
    "    season_df = df[df['赛季'] == season].copy()\n",
    "    weeks = sorted(season_df['第几周'].unique())\n",
    "    \n",
    "    # 确定评分方法\n",
    "    if season <= 2:\n",
    "        scoring_method = 'ranking_early'\n",
    "    elif season <= 27:\n",
    "        scoring_method = 'percentage'\n",
    "    else:\n",
    "        scoring_method = 'ranking_with_save'\n",
    "    \n",
    "    simulation_data = []\n",
    "    for week in weeks:\n",
    "        week_df = season_df[season_df['第几周'] == week]\n",
    "        \n",
    "        # 关键修复: 排除评委分为0的选手\n",
    "        week_df = week_df[week_df['本周评委总分'] > 0]\n",
    "        \n",
    "        if len(week_df) < 3:\n",
    "            continue\n",
    "        \n",
    "        simulation_data.append({\n",
    "            'week': week,\n",
    "            'contestants': week_df['选手姓名'].values,\n",
    "            'judge_scores': week_df['本周评委总分'].values,\n",
    "            'judge_pct': week_df['评委百分比'].values,\n",
    "            'fan_votes': 100 - week_df['评委百分比'].values,  # 代理粉丝投票\n",
    "            'actual_eliminated': week_df[week_df['是否被淘汰']==1]['选手姓名'].tolist(),\n",
    "            'scoring_method': scoring_method,\n",
    "            'has_judges_save': season >= 28\n",
    "        })\n",
    "    \n",
    "    return simulation_data\n",
    "\n",
    "# 选择测试赛季（覆盖三种评分方法）\n",
    "test_seasons = [1, 5, 15, 25, 28, 30, 32]\n",
    "all_sim_data = {s: prepare_simulation_data(df, s) for s in test_seasons}\n",
    "print(f'准备了 {len(test_seasons)} 个赛季的仿真数据')\n",
    "for s in test_seasons:\n",
    "    method = 'ranking_early' if s <= 2 else ('percentage' if s <= 27 else 'ranking_with_save')\n",
    "    print(f'  Season {s}: {len(all_sim_data[s])} weeks, method={method}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 运行仿真对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(sim_data, system, system_name):\n",
    "    \"\"\"运行单个系统的仿真\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for week_data in sim_data:\n",
    "        contestants = week_data['contestants']\n",
    "        judge_scores = week_data['judge_scores']\n",
    "        fan_votes = week_data['fan_votes']\n",
    "        week = week_data['week']\n",
    "        \n",
    "        if system_name == 'Borda':\n",
    "            final_score, final_ranks = system.calculate_final_score(judge_scores, fan_votes)\n",
    "        elif system_name == 'Elo':\n",
    "            final_score, final_ranks = system.calculate_final_score(\n",
    "                contestants, judge_scores, fan_votes, week, len(sim_data)\n",
    "            )\n",
    "            # 更新Elo\n",
    "            for c, r in zip(contestants, final_ranks):\n",
    "                system.update_elo(c, r, len(contestants))\n",
    "        else:  # DualThreshold\n",
    "            final_score, final_ranks = system.calculate_final_score(contestants, judge_scores, fan_votes)\n",
    "        \n",
    "        # 确定淘汰\n",
    "        eliminated_idx = np.argmax(final_ranks)  # 排名最后的被淘汰\n",
    "        \n",
    "        results.append({\n",
    "            'week': week,\n",
    "            'eliminated': contestants[eliminated_idx],\n",
    "            'final_ranks': final_ranks.copy(),\n",
    "            'judge_ranks': stats.rankdata(-judge_scores, method='min')\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 运行所有系统的仿真\n",
    "simulation_results = {}\n",
    "\n",
    "for season in test_seasons:\n",
    "    sim_data = all_sim_data[season]\n",
    "    if not sim_data:\n",
    "        continue\n",
    "    \n",
    "    # 重置Elo系统\n",
    "    elo_system.elo_ratings = {}\n",
    "    \n",
    "    simulation_results[season] = {\n",
    "        'Borda': run_simulation(sim_data, borda_system, 'Borda'),\n",
    "        'Elo': run_simulation(sim_data, elo_system, 'Elo'),\n",
    "        'DualThreshold': run_simulation(sim_data, dual_threshold_system, 'DualThreshold')\n",
    "    }\n",
    "\n",
    "print('仿真完成!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 评估各系统性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(sim_results, original_data):\n",
    "    \"\"\"评估系统性能\"\"\"\n",
    "    fairness_scores = []\n",
    "    stability_scores = []\n",
    "    \n",
    "    for i, (result, orig) in enumerate(zip(sim_results, original_data)):\n",
    "        # 公平性: 评委排名与最终排名的相关性\n",
    "        tau, _ = kendalltau(result['judge_ranks'], result['final_ranks'])\n",
    "        fairness_scores.append((tau + 1) / 2)\n",
    "        \n",
    "        # 稳定性: 排名变化\n",
    "        if i > 0:\n",
    "            prev_ranks = sim_results[i-1]['final_ranks']\n",
    "            curr_ranks = result['final_ranks']\n",
    "            # 只比较共同选手\n",
    "            min_len = min(len(prev_ranks), len(curr_ranks))\n",
    "            if min_len > 0:\n",
    "                change = np.mean(np.abs(prev_ranks[:min_len] - curr_ranks[:min_len]))\n",
    "                stability_scores.append(1 / (1 + change))\n",
    "    \n",
    "    return {\n",
    "        'fairness': np.mean(fairness_scores) if fairness_scores else 0,\n",
    "        'stability': np.mean(stability_scores) if stability_scores else 0,\n",
    "        'entertainment': 1 - np.mean(fairness_scores) * 0.5 if fairness_scores else 0.5  # 简化\n",
    "    }\n",
    "\n",
    "# 评估所有系统\n",
    "evaluation_results = []\n",
    "\n",
    "for season in test_seasons:\n",
    "    if season not in simulation_results:\n",
    "        continue\n",
    "    \n",
    "    orig_data = all_sim_data[season]\n",
    "    \n",
    "    for system_name in ['Borda', 'Elo', 'DualThreshold']:\n",
    "        metrics = evaluate_system(simulation_results[season][system_name], orig_data)\n",
    "        evaluation_results.append({\n",
    "            'Season': season,\n",
    "            'System': system_name,\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "print('Table 1: System Evaluation Results')\n",
    "print(eval_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总统计\n",
    "summary_df = eval_df.groupby('System').agg({\n",
    "    'fairness': ['mean', 'std'],\n",
    "    'stability': ['mean', 'std'],\n",
    "    'entertainment': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "print('\\nTable 2: System Performance Summary')\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 可视化: 系统性能对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(9, 7))\n",
    "\n",
    "systems = ['Borda', 'Elo', 'DualThreshold']\n",
    "system_colors = {s: SCIENTIFIC_COLORS[i] for i, s in enumerate(systems)}\n",
    "\n",
    "# (A) 公平性对比\n",
    "ax1 = axes[0, 0]\n",
    "fairness_by_system = eval_df.groupby('System')['fairness'].mean()\n",
    "ax1.bar(fairness_by_system.index, fairness_by_system.values, \n",
    "        color=[system_colors[s] for s in fairness_by_system.index], alpha=0.8)\n",
    "ax1.set_ylabel('Fairness Score', fontsize=11)\n",
    "ax1.set_title('(A) Fairness Comparison', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# (B) 稳定性对比\n",
    "ax2 = axes[0, 1]\n",
    "stability_by_system = eval_df.groupby('System')['stability'].mean()\n",
    "ax2.bar(stability_by_system.index, stability_by_system.values,\n",
    "        color=[system_colors[s] for s in stability_by_system.index], alpha=0.8)\n",
    "ax2.set_ylabel('Stability Score', fontsize=11)\n",
    "ax2.set_title('(B) Stability Comparison', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# (C) 雷达图\n",
    "ax3 = axes[1, 0]\n",
    "ax3 = plt.subplot(2, 2, 3, projection='polar')\n",
    "\n",
    "categories = ['Fairness', 'Stability', 'Entertainment']\n",
    "angles = [n / float(len(categories)) * 2 * np.pi for n in range(len(categories))]\n",
    "angles += angles[:1]\n",
    "\n",
    "for system in systems:\n",
    "    system_data = eval_df[eval_df['System'] == system]\n",
    "    values = [system_data['fairness'].mean(), system_data['stability'].mean(), system_data['entertainment'].mean()]\n",
    "    values += values[:1]\n",
    "    ax3.plot(angles, values, 'o-', linewidth=2, label=system, color=system_colors[system])\n",
    "    ax3.fill(angles, values, alpha=0.1, color=system_colors[system])\n",
    "\n",
    "ax3.set_xticks(angles[:-1])\n",
    "ax3.set_xticklabels(categories)\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "ax3.set_title('(C) Performance Radar Chart', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "# (D) 按赛季的性能变化\n",
    "ax4 = axes[1, 1]\n",
    "for system in systems:\n",
    "    system_data = eval_df[eval_df['System'] == system]\n",
    "    ax4.plot(system_data['Season'], system_data['fairness'], 'o-', \n",
    "             label=system, color=system_colors[system], linewidth=2, markersize=8)\n",
    "ax4.set_xlabel('Season', fontsize=11)\n",
    "ax4.set_ylabel('Fairness Score', fontsize=11)\n",
    "ax4.set_title('(D) Fairness by Season', fontsize=12, fontweight='bold')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Elo权重动态变化可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# (A) 权重随周数变化\n",
    "ax1 = axes[0]\n",
    "weeks = np.arange(1, 11)\n",
    "judge_weights = [elo_system.get_weights(w, 10)[0] for w in weeks]\n",
    "fan_weights = [elo_system.get_weights(w, 10)[1] for w in weeks]\n",
    "\n",
    "ax1.plot(weeks, judge_weights, 'o-', color=SCIENTIFIC_COLORS[0], linewidth=2, markersize=8, label='Judge Weight')\n",
    "ax1.plot(weeks, fan_weights, 's-', color=SCIENTIFIC_COLORS[1], linewidth=2, markersize=8, label='Fan Weight')\n",
    "ax1.fill_between(weeks, judge_weights, alpha=0.2, color=SCIENTIFIC_COLORS[0])\n",
    "ax1.fill_between(weeks, fan_weights, alpha=0.2, color=SCIENTIFIC_COLORS[1])\n",
    "ax1.set_xlabel('Week', fontsize=11)\n",
    "ax1.set_ylabel('Weight', fontsize=11)\n",
    "ax1.set_title('(A) Elo System: Dynamic Weight Evolution', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# (B) 双重阈值系统示意图\n",
    "ax2 = axes[1]\n",
    "n_contestants = 10\n",
    "immunity_count = dual_threshold_system.get_immunity_count(n_contestants)\n",
    "\n",
    "# 创建示意数据\n",
    "positions = np.arange(1, n_contestants + 1)\n",
    "colors = ['green' if p <= immunity_count else 'orange' for p in positions]\n",
    "\n",
    "ax2.barh(positions, np.ones(n_contestants) * 10, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=immunity_count + 0.5, color='red', linestyle='--', linewidth=2, label='Immunity Threshold')\n",
    "ax2.set_xlabel('Zone', fontsize=11)\n",
    "ax2.set_ylabel('Judge Rank', fontsize=11)\n",
    "ax2.set_title('(B) Dual Threshold: Immunity Zone', fontsize=12, fontweight='bold')\n",
    "ax2.set_yticks(positions)\n",
    "ax2.legend()\n",
    "\n",
    "# 添加标注\n",
    "ax2.text(5, immunity_count/2, 'IMMUNE\\n(Judge Top 30%)', ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "ax2.text(5, (immunity_count + n_contestants)/2, 'AT RISK\\n(Fan Vote Decides)', ha='center', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part III: 学术化统计分析\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 统计检验: 系统间差异显著性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway, kruskal, ttest_ind\n",
    "\n",
    "# ANOVA检验\n",
    "borda_fairness = eval_df[eval_df['System']=='Borda']['fairness'].values\n",
    "elo_fairness = eval_df[eval_df['System']=='Elo']['fairness'].values\n",
    "dual_fairness = eval_df[eval_df['System']=='DualThreshold']['fairness'].values\n",
    "\n",
    "print('=' * 70)\n",
    "print('Table 3: Statistical Tests for System Comparison')\n",
    "print('=' * 70)\n",
    "\n",
    "# ANOVA\n",
    "f_stat, p_value = f_oneway(borda_fairness, elo_fairness, dual_fairness)\n",
    "print(f'One-Way ANOVA (Fairness): F={f_stat:.4f}, p={p_value:.4f}')\n",
    "\n",
    "# Kruskal-Wallis\n",
    "h_stat, p_kw = kruskal(borda_fairness, elo_fairness, dual_fairness)\n",
    "print(f'Kruskal-Wallis H-test: H={h_stat:.4f}, p={p_kw:.4f}')\n",
    "\n",
    "# 效应量 (eta-squared)\n",
    "all_fairness = np.concatenate([borda_fairness, elo_fairness, dual_fairness])\n",
    "grand_mean = np.mean(all_fairness)\n",
    "ss_between = (len(borda_fairness)*(np.mean(borda_fairness)-grand_mean)**2 + \n",
    "              len(elo_fairness)*(np.mean(elo_fairness)-grand_mean)**2 +\n",
    "              len(dual_fairness)*(np.mean(dual_fairness)-grand_mean)**2)\n",
    "ss_total = np.sum((all_fairness - grand_mean)**2)\n",
    "eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
    "print(f'Effect Size (eta-squared): {eta_squared:.4f}')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 事后检验 (Post-hoc Pairwise Comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "systems_data = {\n",
    "    'Borda': borda_fairness,\n",
    "    'Elo': elo_fairness,\n",
    "    'DualThreshold': dual_fairness\n",
    "}\n",
    "\n",
    "print('=' * 70)\n",
    "print('Table 4: Pairwise Comparisons (Bonferroni Corrected)')\n",
    "print('=' * 70)\n",
    "print(f'{\"Comparison\":<25} {\"t-stat\":<12} {\"p-value\":<12} {\"Cohen d\":<12} {\"Significant\":<12}')\n",
    "print('-' * 70)\n",
    "\n",
    "alpha_corrected = 0.05 / 3  # Bonferroni correction\n",
    "\n",
    "for (s1, d1), (s2, d2) in combinations(systems_data.items(), 2):\n",
    "    t_stat, p_val = ttest_ind(d1, d2)\n",
    "    \n",
    "    # Cohen's d\n",
    "    pooled_std = np.sqrt(((len(d1)-1)*np.var(d1) + (len(d2)-1)*np.var(d2)) / (len(d1)+len(d2)-2))\n",
    "    cohens_d = (np.mean(d1) - np.mean(d2)) / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    sig = 'Yes' if p_val < alpha_corrected else 'No'\n",
    "    print(f'{s1} vs {s2:<15} {t_stat:<12.4f} {p_val:<12.4f} {cohens_d:<12.4f} {sig:<12}')\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 敏感性分析: 参数影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不同参数对系统性能的影响\n",
    "sensitivity_results = []\n",
    "\n",
    "# Borda系统: 测试不同judge_weight\n",
    "for jw in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    test_system = WeightedBordaSystem(judge_weight=jw, fan_weight=1-jw)\n",
    "    test_results = run_simulation(all_sim_data[test_seasons[0]], test_system, 'Borda')\n",
    "    metrics = evaluate_system(test_results, all_sim_data[test_seasons[0]])\n",
    "    sensitivity_results.append({\n",
    "        'System': 'Borda',\n",
    "        'Parameter': 'judge_weight',\n",
    "        'Value': jw,\n",
    "        'Fairness': metrics['fairness'],\n",
    "        'Stability': metrics['stability']\n",
    "    })\n",
    "\n",
    "# DualThreshold: 测试不同immunity_ratio\n",
    "for ir in [0.2, 0.3, 0.4, 0.5]:\n",
    "    test_system = DualThresholdSystem(immunity_ratio=ir)\n",
    "    test_results = run_simulation(all_sim_data[test_seasons[0]], test_system, 'DualThreshold')\n",
    "    metrics = evaluate_system(test_results, all_sim_data[test_seasons[0]])\n",
    "    sensitivity_results.append({\n",
    "        'System': 'DualThreshold',\n",
    "        'Parameter': 'immunity_ratio',\n",
    "        'Value': ir,\n",
    "        'Fairness': metrics['fairness'],\n",
    "        'Stability': metrics['stability']\n",
    "    })\n",
    "\n",
    "sens_df = pd.DataFrame(sensitivity_results)\n",
    "print('Table 5: Sensitivity Analysis Results')\n",
    "print(sens_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 敏感性分析可视化\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Borda敏感性\n",
    "ax1 = axes[0]\n",
    "borda_sens = sens_df[sens_df['System'] == 'Borda']\n",
    "ax1.plot(borda_sens['Value'], borda_sens['Fairness'], 'o-', color=SCIENTIFIC_COLORS[0], \n",
    "         linewidth=2, markersize=8, label='Fairness')\n",
    "ax1.plot(borda_sens['Value'], borda_sens['Stability'], 's-', color=SCIENTIFIC_COLORS[1],\n",
    "         linewidth=2, markersize=8, label='Stability')\n",
    "ax1.set_xlabel('Judge Weight', fontsize=11)\n",
    "ax1.set_ylabel('Score', fontsize=11)\n",
    "ax1.set_title('(A) Borda System Sensitivity', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# DualThreshold敏感性\n",
    "ax2 = axes[1]\n",
    "dual_sens = sens_df[sens_df['System'] == 'DualThreshold']\n",
    "ax2.plot(dual_sens['Value'], dual_sens['Fairness'], 'o-', color=SCIENTIFIC_COLORS[2],\n",
    "         linewidth=2, markersize=8, label='Fairness')\n",
    "ax2.plot(dual_sens['Value'], dual_sens['Stability'], 's-', color=SCIENTIFIC_COLORS[3],\n",
    "         linewidth=2, markersize=8, label='Stability')\n",
    "ax2.set_xlabel('Immunity Ratio', fontsize=11)\n",
    "ax2.set_ylabel('Score', fontsize=11)\n",
    "ax2.set_title('(B) Dual Threshold Sensitivity', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 综合评分与最终推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算综合评分\n",
    "final_scores = []\n",
    "\n",
    "for system in ['Borda', 'Elo', 'DualThreshold']:\n",
    "    system_data = eval_df[eval_df['System'] == system]\n",
    "    \n",
    "    fairness = system_data['fairness'].mean()\n",
    "    stability = system_data['stability'].mean()\n",
    "    entertainment = system_data['entertainment'].mean()\n",
    "    \n",
    "    # 综合评分 (加权平均)\n",
    "    overall = 0.35 * fairness + 0.25 * stability + 0.25 * entertainment + 0.15 * 0.8  # 实现复杂度\n",
    "    \n",
    "    final_scores.append({\n",
    "        'System': system,\n",
    "        'Fairness': fairness,\n",
    "        'Stability': stability,\n",
    "        'Entertainment': entertainment,\n",
    "        'Overall': overall\n",
    "    })\n",
    "\n",
    "final_df = pd.DataFrame(final_scores).sort_values('Overall', ascending=False)\n",
    "\n",
    "print('=' * 80)\n",
    "print('Table 6: Final System Ranking')\n",
    "print('=' * 80)\n",
    "print(final_df.round(4).to_string(index=False))\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终推荐可视化\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "systems = final_df['System'].values\n",
    "overall_scores = final_df['Overall'].values\n",
    "colors = [SCIENTIFIC_COLORS[i] for i in range(len(systems))]\n",
    "\n",
    "bars = ax.barh(systems, overall_scores, color=colors, alpha=0.8)\n",
    "\n",
    "# 添加数值标签\n",
    "for bar, score in zip(bars, overall_scores):\n",
    "    ax.text(score + 0.01, bar.get_y() + bar.get_height()/2, f'{score:.3f}',\n",
    "            va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Overall Score', fontsize=12)\n",
    "ax.set_title('Final System Recommendation Ranking', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "# 添加推荐标记\n",
    "ax.annotate('RECOMMENDED', xy=(overall_scores[0], 0), xytext=(overall_scores[0]-0.15, 0.3),\n",
    "            fontsize=10, fontweight='bold', color='green',\n",
    "            arrowprops=dict(arrowstyle='->', color='green'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 综合结论与政策建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_system = final_df.iloc[0]['System']\n",
    "best_score = final_df.iloc[0]['Overall']\n",
    "\n",
    "print('=' * 80)\n",
    "print('问题4 研究结论与政策建议')\n",
    "print('=' * 80)\n",
    "\n",
    "print(f'''\n",
    "1. 三种新赛制方案对比:\n",
    "\n",
    "   方案A - 加权Borda计数法:\n",
    "   - 优点: 兼顾名次和表现差距，防止一人独大\n",
    "   - 缺点: 计算相对复杂，观众理解成本高\n",
    "   - 公平性: {eval_df[eval_df[\"System\"]==\"Borda\"][\"fairness\"].mean():.3f}\n",
    "\n",
    "   方案B - Elo动态权重系统:\n",
    "   - 优点: 增加比赛后期悬念，奖励持续稳定表现\n",
    "   - 缺点: 需要维护历史数据，新选手可能处于劣势\n",
    "   - 公平性: {eval_df[eval_df[\"System\"]==\"Elo\"][\"fairness\"].mean():.3f}\n",
    "\n",
    "   方案C - 双重阈值淘汰制:\n",
    "   - 优点: 规则简单明了，绝对保护技术最好的选手\n",
    "   - 缺点: 可能降低顶尖选手的紧张感\n",
    "   - 公平性: {eval_df[eval_df[\"System\"]==\"DualThreshold\"][\"fairness\"].mean():.3f}\n",
    "\n",
    "2. 最终推荐: {best_system}\n",
    "   - 综合评分: {best_score:.4f}\n",
    "   - 推荐理由: 在公平性、稳定性和观赏性之间取得最佳平衡\n",
    "\n",
    "3. 实施建议:\n",
    "   - 建议在试点赛季先行测试新赛制\n",
    "   - 收集观众反馈，根据实际效果微调参数\n",
    "   - 考虑结合多种方案的优点，设计混合赛制\n",
    "\n",
    "4. 未来研究方向:\n",
    "   - 引入更多评估维度（如收视率、社交媒体热度）\n",
    "   - 使用强化学习优化参数设置\n",
    "   - 考虑选手心理因素对表现的影响\n",
    "''')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. 导出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存分析结果\n",
    "\n",
    "print('结果已保存至 figures/ 目录')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmericaMathModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
